---
---

@article{ml_probabilistic_perspective,
  abbr={Ann. Phys.},
  title={MAchine Learning: A Probabilistic Perspective},
  author={Kevin P. Murphy},
  year={2012}
}

@article{articulatory_inversion,
  title={Deep Architectures for Articulatory Inversion},
  author={Uria, et al.},
  year={2012},
  url={https://publications.aston.ac.uk/id/eprint/373/1/NCRG_94_004.pdf}
}

@article{mixture_density_network,
  title={Mixture Density Networks},
  author={Bishop},
  year={2024},
  url={https://publications.aston.ac.uk/id/eprint/373/1/NCRG_94_004.pdf}
}
@article{mixtral_of_experts,
  title={Mixtral Of Experts},
  author={Jiang, et al.},
  year={2024},
  url={https://arxiv.org/pdf/2401.04088}
}
@article{deepseekmoe,
  title={DeepSeekMoE: Towards Ultimate Expert Specialization in
Mixture-of-Experts Language Models},
  author={Dai, et al.},
  year={2024},
  url={https://arxiv.org/pdf/2401.06066}
}

@article{sparse_moe,
  title={Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer},
  author={Shazeer, et al.},
  year={2017},
  url={https://arxiv.org/pdf/1701.06538}
}

@article{gshard,
  title={GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding},
  author={Lepikhin, et al.},
  year={2020},
  url={https://arxiv.org/pdf/2006.16668}
}

@article{loss_free_balancing,
  title={Auxiliary-Loss-Free Load Balancing Strategy for Mixture-of-Experts},
  author={Wang, et al.},
  year={2024},
  url={https://arxiv.org/pdf/2408.15664}
}
